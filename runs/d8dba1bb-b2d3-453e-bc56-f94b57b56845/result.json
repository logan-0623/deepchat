{"status": "success", "type": "pdf", "task_id": "d8dba1bb-b2d3-453e-bc56-f94b57b56845", "file_name": "d8dba1bb-b2d3-453e-bc56-f94b57b56845_36671a07cd9a2443d83ed76dd43a136c.pdf", "content": "\n--- 第 1 页 ---\nLecture 9 -- OverfittingProf. Xiaowei Huanghttps://cgi.csc.liv.ac.uk/~xiaowei/(Attendance Code: 488324) \n\n--- 第 2 页 ---\nDecision Tree up to now, Decision tree representationA general top-down algorithmHow to do splitting on numeric featuresPrinciple of Decision Tree ConstructionEntropy and information gain \n--- 第 3 页 ---\nToday ’s Topics1.Stopping criteria of decision trees2.Accuracy of decision trees3.Pruning and validation dataset4.Overfitting5.Overfitting in decision tree \n--- 第 4 页 ---\n1. Step (3): Stopping criteria \n--- 第 5 页 ---\nStopping criteria •We should form a leaf when •all of the given subset of instances are of the same class, or  •we’ve exhausted all of the candidate splits \n\n--- 第 6 页 ---\n2. Accuracy of Decision Tree\n\n--- 第 7 页 ---\nDefinition of Accuracy and Error•Given a set D of samples and a trained model M, the accuracy is the percentage of correctly labeled samples. That is, Where     is the true label of sample     and           gives the predicted label of      by •Error is a dual concept of accuracy.  \nBut, what is D?lx\n<latexit sha1_base64=\"Ca0OMMM1US9dGQy18FhfhUjU8zY=\">AAAB6nicbVBNS8NAEJ34WetX1aOXxSJ4KkkV9Fj04rGi/YA2lM120i7dbMLuRiyhP8GLB0W8+ou8+W/ctjlo64OBx3szzMwLEsG1cd1vZ2V1bX1js7BV3N7Z3dsvHRw2dZwqhg0Wi1i1A6pRcIkNw43AdqKQRoHAVjC6mfqtR1Sax/LBjBP0IzqQPOSMGivdi95Tr1R2K+4MZJl4OSlDjnqv9NXtxyyNUBomqNYdz02Mn1FlOBM4KXZTjQllIzrAjqWSRqj9bHbqhJxapU/CWNmShszU3xMZjbQeR4HtjKgZ6kVvKv7ndVITXvkZl0lqULL5ojAVxMRk+jfpc4XMiLEllClubyVsSBVlxqZTtCF4iy8vk2a14p1XqncX5dp1HkcBjuEEzsCDS6jBLdShAQwG8Ayv8OYI58V5dz7mrStOPnMEf+B8/gBmUo3f</latexit>x<latexit sha1_base64=\"hL+FaLtOT9luwfLW3Ut08xl3Pcw=\">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHbRRI9ELx4hkUcCGzI79MLI7OxmZtZICF/gxYPGePWTvPk3DrAHBSvppFLVne6uIBFcG9f9dnJr6xubW/ntws7u3v5B8fCoqeNUMWywWMSqHVCNgktsGG4EthOFNAoEtoLR7cxvPaLSPJb3ZpygH9GB5CFn1Fip/tQrltyyOwdZJV5GSpCh1it+dfsxSyOUhgmqdcdzE+NPqDKcCZwWuqnGhLIRHWDHUkkj1P5kfuiUnFmlT8JY2ZKGzNXfExMaaT2OAtsZUTPUy95M/M/rpCa89idcJqlByRaLwlQQE5PZ16TPFTIjxpZQpri9lbAhVZQZm03BhuAtv7xKmpWyd1Gu1C9L1ZssjjycwCmcgwdXUIU7qEEDGCA8wyu8OQ/Oi/PufCxac042cwx/4Hz+AOeHjQA=</latexit>M(x)\n<latexit sha1_base64=\"OovD2S9Nuz/cvAu5ChGJZm0eqG4=\">AAAB63icbVBNSwMxEJ2tX7V+VT16CRahXspuFfRY9OJFqGBroV1KNs22oUl2SbJiWfoXvHhQxKt/yJv/xmy7B219MPB4b4aZeUHMmTau++0UVlbX1jeKm6Wt7Z3dvfL+QVtHiSK0RSIeqU6ANeVM0pZhhtNOrCgWAacPwfg68x8eqdIskvdmElNf4KFkISPYZNJt9em0X664NXcGtEy8nFQgR7Nf/uoNIpIIKg3hWOuu58bGT7EyjHA6LfUSTWNMxnhIu5ZKLKj209mtU3RilQEKI2VLGjRTf0+kWGg9EYHtFNiM9KKXif953cSEl37KZJwYKsl8UZhwZCKUPY4GTFFi+MQSTBSztyIywgoTY+Mp2RC8xZeXSbte885q9bvzSuMqj6MIR3AMVfDgAhpwA01oAYERPMMrvDnCeXHenY95a8HJZw7hD5zPH0d+jbw=</latexit>x<latexit sha1_base64=\"hL+FaLtOT9luwfLW3Ut08xl3Pcw=\">AAAB6HicbVDLTgJBEOzFF+IL9ehlIjHxRHbRRI9ELx4hkUcCGzI79MLI7OxmZtZICF/gxYPGePWTvPk3DrAHBSvppFLVne6uIBFcG9f9dnJr6xubW/ntws7u3v5B8fCoqeNUMWywWMSqHVCNgktsGG4EthOFNAoEtoLR7cxvPaLSPJb3ZpygH9GB5CFn1Fip/tQrltyyOwdZJV5GSpCh1it+dfsxSyOUhgmqdcdzE+NPqDKcCZwWuqnGhLIRHWDHUkkj1P5kfuiUnFmlT8JY2ZKGzNXfExMaaT2OAtsZUTPUy95M/M/rpCa89idcJqlByRaLwlQQE5PZ16TPFTIjxpZQpri9lbAhVZQZm03BhuAtv7xKmpWyd1Gu1C9L1ZssjjycwCmcgwdXUIU7qEEDGCA8wyu8OQ/Oi/PufCxac042cwx/4Hz+AOeHjQA=</latexit>M<latexit sha1_base64=\"LYKb6VVKloxBSLpM78v6ttRQbOI=\">AAAB6HicbVDLSgNBEOyNrxhfUY9eBoPgKexGQY9BL16EBMwDkiXMTnqTMbOzy8ysEEK+wIsHRbz6Sd78GyfJHjSxoKGo6qa7K0gE18Z1v53c2vrG5lZ+u7Czu7d/UDw8auo4VQwbLBaxagdUo+ASG4Ybge1EIY0Cga1gdDvzW0+oNI/lgxkn6Ed0IHnIGTVWqt/3iiW37M5BVomXkRJkqPWKX91+zNIIpWGCat3x3MT4E6oMZwKnhW6qMaFsRAfYsVTSCLU/mR86JWdW6ZMwVrakIXP198SERlqPo8B2RtQM9bI3E//zOqkJr/0Jl0lqULLFojAVxMRk9jXpc4XMiLEllClubyVsSBVlxmZTsCF4yy+vkmal7F2UK/XLUvUmiyMPJ3AK5+DBFVThDmrQAAYIz/AKb86j8+K8Ox+L1pyTzRzDHzifP6ZbjNU=</latexit>\n--- 第 8 页 ---\nHow can we assess the accuracy of a tree? •Can we just calculate the fraction of training instancesthat are correctly classified?•Consider a problem domain in which instances are assigned labels at random with P(Y = t) = 0.5 •how accurate would a learned decision tree be on previously unseen instances? •Can never reach 1.0. •how accurate would it be on its training set? •Can be arbitrarily close to, or reach, 1.0 if model can be very large. D = training datasetGround truth\n--- 第 9 页 ---\nHow can we assess the accuracy of a tree? •to get an unbiased estimate of a learned model’s accuracy, we must use a set of instances that are held-aside during learning •this is called a test set \n\n--- 第 10 页 ---\n3. Pruning and Validation Dataset\n--- 第 11 页 ---\nStopping criteria •We should form a leaf when •all of the given subset of instances are of the same class •we’ve exhausted all of the candidate splits •Is there a reason to stop earlier, or to prune back the tree? \n\n--- 第 12 页 ---\nPruning in C4.5 \n•Split given data into training and validation(tuning) sets •A validation set (a.k.a. tuning set) is a subset of the training set that is held aside •not used for primary training process (e.g. tree growing) •but used to select among models (e.g. trees pruned to varying degrees) \n\n--- 第 13 页 ---\nPruning in C4.5 \n•Split given data into training and validation (tuning) sets •Grow a complete tree•do until further pruning is harmful •evaluate impact on tuning-set accuracy of pruning each node •greedily remove the one that least reduces tuning-set accuracy \n\n--- 第 14 页 ---\n4. Overfitting\n--- 第 15 页 ---\nExample 3: regression using polynomial \nRegression using polynomial of degree My = wMxM+ wM-1xM-1+ … + w1x + w0\n--- 第 16 页 ---\nExample 3: regression using polynomial \ny = c \n--- 第 17 页 ---\nExample 3: regression using polynomial \ny = w1x + w0\n--- 第 18 页 ---\nExample 3: regression using polynomial \ny = w3x3+ w2x2+ w1x + w0\n--- 第 19 页 ---\nExample 3: regression using polynomial \ny = w9x9+ w8x8+ … + w1x + w0Overfits, why?\n--- 第 20 页 ---\nExample: regression using polynomial \nRMS: root mean square, i.e., thesquare rootof themean square\n--- 第 21 页 ---\nGeneral phenomenon \n\n--- 第 22 页 ---\nOverfitting in decision trees \n\n--- 第 23 页 ---\nPrevent overfitting •Cause: training error and expected error are different •there may be noise in the training data •training data is of limited size, resulting in difference from the true distribution •the larger the hypothesis class, the easier to find a hypothesis that fits the difference between the training data and the true distribution •How to reduce overfitting: •cleaner training data help! •more training data help! •throwing away unnecessary hypotheses helps! (Occam’s Razor) Large modelSmall training datasetWill have examples in decision tree later for these two cases\n--- 第 24 页 ---\n5. Overfitting in Decision Tree\n\n--- 第 25 页 ---\nOverfitting •Consider error of model M over •training data: •entire distribution of data: •Model               overfitsthe training data if there is an alternative model such that Perform better on training datasetPerform worse on true distribution\n\n--- 第 26 页 ---\nExample 1: overfitting with noisy data •suppose •the target concept is •there is noise in some feature values •we’re given the following training set \nGround truth\n--- 第 27 页 ---\nExample 1: overfitting with noisy data \nA noisy data sample:X1 = tX2 = fX3 = tX4 = tX5 = fY = t\n\n--- 第 28 页 ---\nExample 1: overfitting with noisy data \nWhat is the accuracy? •Accuracy(Dtraining,M) = 5/6•Accuracy(Dtrue,M) = 100%\n--- 第 29 页 ---\nExample 1: overfitting with noisy data \nWhat is the accuracy? •Accuracy(Dtraining,M) = 100%•Accuracy(Dtrue,M) < 100%\n--- 第 30 页 ---\nExample 1: overfitting with noisy data \nTraining set accuracyTrue accuracy5/6100%100%< 100 %M2 is overfitting!M1M2\n--- 第 31 页 ---\nExample 2: overfitting with noise-free data •suppose •the target concept is•P(X3= t) = 0.5 for both classes •P(Y = t) = 0.66 •we’re given the following training set \nGround truth\n--- 第 32 页 ---\nExample 2: overfitting with noise-free data \nM1M2\n--- 第 33 页 ---\nExample 2: overfitting with noise-free data \nP(X3 = t) = 0.5P(Y=t) = 0.66\nWhat is the accuracy? •Accuracy(Dtraining,M) = 100%•Accuracy(Dtrue,M) = 50%(X3, Y):   (t, t) = 0.5*0.66 (correct)  (t, f) = 0.5*0.33 (fail)  (f, t) = 0.5 *0.66 (fail)  (f, f) = 0.5 *0.33 (correct)So, we have 50% correctness\n--- 第 34 页 ---\nExample 2: overfitting with noise-free data \nP(X3 = t) = 0.5P(Y=t) = 0.66\nWhat is the accuracy? •Accuracy(Dtraining,M) = 60%•Accuracy(Dtrue,M) = 66%\n--- 第 35 页 ---\nExample 2: overfitting with noise-free data \nTraining set accuracyTrue accuracy100%50%60%66%M1M2M1 is overfitting!because the training set is a limited sample, there might be (combinations of) features that are correlated with the target concept by chance \n--- 第 36 页 ---\nAvoiding overfitting in DT learning •two general strategies to avoid overfitting 1.early stopping:stop if further splitting not justified by a statistical test •Quinlan’s original approach in ID3 2.post-pruning: grow a large tree, then prune back some nodes •more robust to myopia of greedy tree learning The stopping criterion utilizing validation dataset"}