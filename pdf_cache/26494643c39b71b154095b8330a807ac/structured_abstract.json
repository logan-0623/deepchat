{"abstract": "**Abstract**  \n• A novel Multi-modal Time Series Analysis Model Based on Spiking Neural Network (MTSA-SNN) is proposed  \n• The model integrates pulse encoding, joint learning, and wavelet transform for complex time-series analysis  \n• Experimental results demonstrate superior performance on three diverse time-series datasets  \n• The source code is publicly available for reproducibility  \n\n**Introduction**  \n• Traditional Artificial Neural Networks (ANNs) struggle with non-stationary time-series data due to high computational complexity  \n• Spiking Neural Networks (SNNs) offer advantages in temporal information processing but face challenges in multi-modal fusion  \n• MTSA-SNN addresses these limitations through innovative pulse encoding and joint learning mechanisms  \n• The model combines wavelet transform for enhanced multi-scale feature extraction  \n\n**Related Work**  \n• Existing approaches like Long Short-Term Memory (LSTM) and Autoformer lack efficient event-driven processing  \n• Multi-modal time series analysis typically relies on continuous computations, limiting adaptability  \n• Recent SNN variants show promise but struggle with cross-modal synchronization and stability  \n• Wavelet transform has been underutilized in neural network-based time series analysis  \n\n**Methodology**  \n• The Pulse Encoder converts multi-modal data ($S_{image}$, $S_{series}$) into unified spike representations ($\\hat{S}_1$, $\\hat{S}_2$)  \n• Leaky Integrate-and-Fire (LIF) model dynamics are governed by membrane potential equations: $\\tau_m\\frac{dV(t)}{dt} = -(V(t)-V_{rest}) + R\\cdot I(t)$  \n• Joint Learning Module employs Fourier transform ($FT(s) = \\int_{-\\infty}^{\\infty}\\hat{S}\\odot e^{-iwT}$) and weight allocation ($P_{mtsa}$) for cross-modal fusion  \n• Wavelet transform decomposes signals into LL, LH, HL, HH subbands for multi-scale analysis  \n\n**Experiment**  \n• Evaluated on MIT-BIH Arrhythmia (98.75% accuracy), Electricity Transformer Temperature (ETT) (MSE 0.235), and stock market datasets (MAE 0.961)  \n• Outperforms benchmarks (LSTM, XGBoost, Autoformer) by 12-47% across metrics  \n• Ablation studies confirm 23% performance gain from wavelet integration  \n• Neuron activation heatmaps demonstrate enhanced temporal feature representation  \n\n**Conclusion**  \n• MTSA-SNN establishes new state-of-the-art for multi-modal time series analysis  \n• The pulse-based framework effectively handles non-stationary and event-driven data  \n• Wavelet integration significantly improves multi-scale feature extraction  \n• Future work will explore biological signal processing applications"}